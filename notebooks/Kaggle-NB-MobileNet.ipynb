{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Convulotional Neural Networks**","metadata":{}},{"cell_type":"markdown","source":"The followings code are inspired from\n\"Image Preparation for Convolutional Neural Networks with TensorFlow's Keras API\" video by deeplizard","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.models import Model\nimport itertools\nimport os\nimport shutil\nimport random\nimport glob\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.simplefilter (action='ignore', category=FutureWarning)\n%matplotlib inline\n\nprint(np.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:37.668131Z","iopub.execute_input":"2023-11-09T14:34:37.668573Z","iopub.status.idle":"2023-11-09T14:34:46.430845Z","shell.execute_reply.started":"2023-11-09T14:34:37.668539Z","shell.execute_reply":"2023-11-09T14:34:46.429924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for available GPUs and set memory growth for the first GPU\n\n# List all available physical devices (including GPUs)\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\n\n# Print the number of available GPUs\nprint(\"Num GPUs Available: \", len(physical_devices))\n\n# Set memory growth for the first GPU (assuming at least one GPU is available)\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:46.432688Z","iopub.execute_input":"2023-11-09T14:34:46.433252Z","iopub.status.idle":"2023-11-09T14:34:46.791362Z","shell.execute_reply.started":"2023-11-09T14:34:46.433212Z","shell.execute_reply":"2023-11-09T14:34:46.790333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data preparation**","metadata":{}},{"cell_type":"code","source":"# Change the current working directory to '/kaggle/working'\nos.chdir('/kaggle/working')\n\n# Define the source directory where the dataset is located\nsource_directory = '/kaggle/input/laguna-banana-dataset-preprocessed/laguna_dataset_preprocessed'\n\n# # Define the path to the directory you want to remove\n# directory_to_remove = 'laguna_dataset_preprocessed'\n#  # If it exists, remove it\n# shutil.rmtree(directory_to_remove)\n    \n# Check if a directory named 'dogcat_dataset' does not exist\nif os.path.isdir('laguna_dataset_preprocessed') is False:\n    # If 'dogcat_dataset' does not exist, copy the contents of 'source_directory' to 'dogcat_dataset'\n    shutil.copytree(source_directory, 'laguna_dataset_preprocessed')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:46.792655Z","iopub.execute_input":"2023-11-09T14:34:46.793002Z","iopub.status.idle":"2023-11-09T14:34:46.805229Z","shell.execute_reply.started":"2023-11-09T14:34:46.792974Z","shell.execute_reply":"2023-11-09T14:34:46.804302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define paths for training, validation, and test sets\ntrain_path = '/kaggle/working/laguna_dataset_preprocessed/train'\nvalid_path = '/kaggle/working/laguna_dataset_preprocessed/valid'\ntest_path = '/kaggle/working/laguna_dataset_preprocessed/test'\n\n# Check if the directories exist and print the results\nprint(os.path.isdir(train_path))  # Check if 'train' directory exists\nprint(os.path.isdir(valid_path))  # Check if 'valid' directory exists\nprint(os.path.isdir(test_path))   # Check if 'test' directory exists\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:46.806615Z","iopub.execute_input":"2023-11-09T14:34:46.807086Z","iopub.status.idle":"2023-11-09T14:34:46.818463Z","shell.execute_reply.started":"2023-11-09T14:34:46.807054Z","shell.execute_reply":"2023-11-09T14:34:46.817583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define an ImageDataGenerator for data augmentation and preprocessing using MobileNet settings\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,  # Increased rotation range\n    width_shift_range=0.2,  # Increased shift range\n    height_shift_range=0.2,  # Increased shift range\n    shear_range=0.2,  # Increased shear range\n    zoom_range=0.2,  # Increased zoom range\n    channel_shift_range=20.,  # Increased channel shift range\n    horizontal_flip=True,\n    preprocessing_function=tf.keras.applications.mobilenet.preprocess_input\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:46.820831Z","iopub.execute_input":"2023-11-09T14:34:46.821137Z","iopub.status.idle":"2023-11-09T14:34:46.832115Z","shell.execute_reply.started":"2023-11-09T14:34:46.821080Z","shell.execute_reply":"2023-11-09T14:34:46.831351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile = tf.keras.applications.mobilenet.MobileNet()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:46.833426Z","iopub.execute_input":"2023-11-09T14:34:46.833850Z","iopub.status.idle":"2023-11-09T14:34:50.350058Z","shell.execute_reply.started":"2023-11-09T14:34:46.833823Z","shell.execute_reply":"2023-11-09T14:34:50.349048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define ImageDataGenerator and generate batches of images\n# Apply data augmentation to the training batch\ntrain_batches = train_datagen.flow_from_directory(\n    directory=train_path,\n    target_size=(224, 224), classes=['Black sigatoka', 'Bunchy top', 'Healthy'], batch_size=10)\n\n# Validation set\nvalid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=valid_path, target_size=(224,224), classes=['Black sigatoka', 'Bunchy top', 'Healthy'], batch_size=10)\n\n# Test set\ntest_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=test_path, target_size=(224,224), classes=['Black sigatoka', 'Bunchy top', 'Healthy'], batch_size=10, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:50.351297Z","iopub.execute_input":"2023-11-09T14:34:50.351589Z","iopub.status.idle":"2023-11-09T14:34:50.395676Z","shell.execute_reply.started":"2023-11-09T14:34:50.351564Z","shell.execute_reply":"2023-11-09T14:34:50.394896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assertions to validate properties of the generated batches\n\n# Ensure that there are 2000 images in the training set\nassert train_batches.n == 627\n\n# Ensure that there are 400 images in the validation set\nassert valid_batches.n == 177\n\n# Ensure that there are 200 images in the test set\nassert test_batches.n == 79\n\n# Ensure that the number of classes is 3 for all sets (Black sigatoka, Bunchy top, Healthy)\nassert train_batches.num_classes == valid_batches.num_classes == test_batches.num_classes == 3\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:50.396703Z","iopub.execute_input":"2023-11-09T14:34:50.396983Z","iopub.status.idle":"2023-11-09T14:34:50.402486Z","shell.execute_reply.started":"2023-11-09T14:34:50.396957Z","shell.execute_reply":"2023-11-09T14:34:50.401444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate a batch of images and their corresponding labels\n\n# Use the 'next' method to get the next batch of images and labels from the training set\nimgs, labels = next(train_batches)\n# Print out the labels\nprint(labels)\n\n# # One-hot encode the labels\n# from tensorflow.keras.utils import to_categorical\n# one_hot_labels = to_categorical(labels, num_classes=3)\n\n# # Print out the one-hot encoded labels\n# print(one_hot_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:50.403672Z","iopub.execute_input":"2023-11-09T14:34:50.403949Z","iopub.status.idle":"2023-11-09T14:34:51.601008Z","shell.execute_reply.started":"2023-11-09T14:34:50.403924Z","shell.execute_reply":"2023-11-09T14:34:51.599963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to plot a series of images\n\ndef plotImages(images_arr):\n    # Create a figure with 10 subplots arranged in 1 row and 10 columns\n    fig, axes = plt.subplots(1, 3, figsize=(20,20))\n    \n    # Flatten the array of axes to make it easier to iterate over\n    axes = axes.flatten()\n    \n    # Iterate through the images and corresponding axes\n    for img, ax in zip(images_arr, axes):\n        # Display the image on the current axis\n        ax.imshow(img)\n        \n        # Turn off axis labels for better visualization\n        ax.axis('off')\n    \n    # Adjust the layout to prevent overlapping\n    plt.tight_layout()\n    \n    # Display the figure with the images\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:51.602439Z","iopub.execute_input":"2023-11-09T14:34:51.603275Z","iopub.status.idle":"2023-11-09T14:34:51.609704Z","shell.execute_reply.started":"2023-11-09T14:34:51.603238Z","shell.execute_reply":"2023-11-09T14:34:51.608842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the images in 'imgs' and print the corresponding labels\n\n# Call the previously defined function 'plotImages' to display the images\nplotImages(imgs)\n\n# Print the labels corresponding to the displayed images\nprint(labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:51.610771Z","iopub.execute_input":"2023-11-09T14:34:51.611053Z","iopub.status.idle":"2023-11-09T14:34:52.265353Z","shell.execute_reply.started":"2023-11-09T14:34:51.611028Z","shell.execute_reply":"2023-11-09T14:34:52.264388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Build a Fine-Tuned MobileNet model**","metadata":{}},{"cell_type":"markdown","source":"The following codes are inspired from \"Build a Fine-Tuned Neural Network with TensorFlow's Keras API\" video by deeplizard","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:52.266580Z","iopub.execute_input":"2023-11-09T14:34:52.266872Z","iopub.status.idle":"2023-11-09T14:34:52.274093Z","shell.execute_reply.started":"2023-11-09T14:34:52.266846Z","shell.execute_reply":"2023-11-09T14:34:52.273049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile = tf.keras.applications.mobilenet.MobileNet()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:52.275328Z","iopub.execute_input":"2023-11-09T14:34:52.275598Z","iopub.status.idle":"2023-11-09T14:34:53.195534Z","shell.execute_reply.started":"2023-11-09T14:34:52.275575Z","shell.execute_reply":"2023-11-09T14:34:53.194681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.201334Z","iopub.execute_input":"2023-11-09T14:34:53.201662Z","iopub.status.idle":"2023-11-09T14:34:53.390815Z","shell.execute_reply.started":"2023-11-09T14:34:53.201635Z","shell.execute_reply":"2023-11-09T14:34:53.389857Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_params(model):\n    non_trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in model.non_trainable_weights])\n    trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in model.trainable_weights])\n    return {'non_trainable_params': non_trainable_params, 'trainable_params': trainable_params}","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.392254Z","iopub.execute_input":"2023-11-09T14:34:53.392626Z","iopub.status.idle":"2023-11-09T14:34:53.399307Z","shell.execute_reply.started":"2023-11-09T14:34:53.392592Z","shell.execute_reply":"2023-11-09T14:34:53.398408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = count_params(mobile)\nassert params['non_trainable_params'] == 21888\nassert params['trainable_params'] == 4231976","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.400608Z","iopub.execute_input":"2023-11-09T14:34:53.401032Z","iopub.status.idle":"2023-11-09T14:34:53.416445Z","shell.execute_reply.started":"2023-11-09T14:34:53.400998Z","shell.execute_reply":"2023-11-09T14:34:53.415452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = mobile.layers[-5].output\n\nx = tf.keras.layers.Reshape(target_shape=(1024,))(x)\n\nx = Dropout(0.8)(x)  # Add dropout layer\n\noutput = Dense(units=3, activation='softmax', \n               kernel_regularizer=regularizers.l1_l2(l1=0.1, l2=0.1))(x)  # ElasticNet Regularization","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.417655Z","iopub.execute_input":"2023-11-09T14:34:53.417944Z","iopub.status.idle":"2023-11-09T14:34:53.462464Z","shell.execute_reply.started":"2023-11-09T14:34:53.417920Z","shell.execute_reply":"2023-11-09T14:34:53.461434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=mobile.input, outputs=output)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.463551Z","iopub.execute_input":"2023-11-09T14:34:53.463859Z","iopub.status.idle":"2023-11-09T14:34:53.477754Z","shell.execute_reply.started":"2023-11-09T14:34:53.463825Z","shell.execute_reply":"2023-11-09T14:34:53.476671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in model.layers[:-50]:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.479092Z","iopub.execute_input":"2023-11-09T14:34:53.479470Z","iopub.status.idle":"2023-11-09T14:34:53.486943Z","shell.execute_reply.started":"2023-11-09T14:34:53.479437Z","shell.execute_reply":"2023-11-09T14:34:53.485998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.488465Z","iopub.execute_input":"2023-11-09T14:34:53.488740Z","iopub.status.idle":"2023-11-09T14:34:53.686873Z","shell.execute_reply.started":"2023-11-09T14:34:53.488716Z","shell.execute_reply":"2023-11-09T14:34:53.685905Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# params = count_params (model)\n# assert params['non_trainable_params'] == 1371840\n# assert params['trainable_params'] == 1860099","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.688041Z","iopub.execute_input":"2023-11-09T14:34:53.688362Z","iopub.status.idle":"2023-11-09T14:34:53.692441Z","shell.execute_reply.started":"2023-11-09T14:34:53.688336Z","shell.execute_reply":"2023-11-09T14:34:53.691526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Train the Fine-Tuned MobileNet model**","metadata":{}},{"cell_type":"markdown","source":"The following codes are inspired from \"Train a Fine-Tuned Neural Network with TensorFlow's Keras API\" video by deeplizard","metadata":{}},{"cell_type":"code","source":"num_Bunchy_top_samples = len(os.listdir('/kaggle/working/laguna_dataset_preprocessed/test/Bunchy top'))\nnum_Black_sigatoka_samples = len(os.listdir('/kaggle/working/laguna_dataset_preprocessed/test/Black sigatoka'))\nnum_Healthy_samples = len(os.listdir('/kaggle/working/laguna_dataset_preprocessed/test/Healthy'))\n\nprint(\"Number of Bunchy top samples:\", num_Bunchy_top_samples)\nprint(\"Number of Black sigatoka samples:\", num_Black_sigatoka_samples)\nprint(\"Number of Healthy samples:\", num_Healthy_samples)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.693554Z","iopub.execute_input":"2023-11-09T14:34:53.693838Z","iopub.status.idle":"2023-11-09T14:34:53.705127Z","shell.execute_reply.started":"2023-11-09T14:34:53.693805Z","shell.execute_reply":"2023-11-09T14:34:53.704156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# early_stopping = EarlyStopping(monitor='val_loss', patience=7)  # Adjust patience as needed\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.706351Z","iopub.execute_input":"2023-11-09T14:34:53.706649Z","iopub.status.idle":"2023-11-09T14:34:53.715026Z","shell.execute_reply.started":"2023-11-09T14:34:53.706625Z","shell.execute_reply":"2023-11-09T14:34:53.714150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-4,\n    decay_steps=1000,\n    decay_rate=0.9)\noptimizer = Adam(learning_rate=lr_schedule)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.716476Z","iopub.execute_input":"2023-11-09T14:34:53.717145Z","iopub.status.idle":"2023-11-09T14:34:53.754166Z","shell.execute_reply.started":"2023-11-09T14:34:53.717094Z","shell.execute_reply":"2023-11-09T14:34:53.753172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.755614Z","iopub.execute_input":"2023-11-09T14:34:53.755901Z","iopub.status.idle":"2023-11-09T14:34:53.773851Z","shell.execute_reply.started":"2023-11-09T14:34:53.755876Z","shell.execute_reply":"2023-11-09T14:34:53.772777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=train_batches,\n            steps_per_epoch=len(train_batches),\n            validation_data=valid_batches,\n            validation_steps=len(valid_batches),\n            epochs=20,\n            verbose=2,\n            callbacks=[early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:34:53.775141Z","iopub.execute_input":"2023-11-09T14:34:53.775466Z","iopub.status.idle":"2023-11-09T14:59:43.820014Z","shell.execute_reply.started":"2023-11-09T14:34:53.775440Z","shell.execute_reply":"2023-11-09T14:59:43.818969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve training and validation accuracy from the training history\ntrain_accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\n\n# Create a list of epochs for the x-axis\nepochs = range(1, len(train_accuracy) + 1)\n\n# Plot the training and validation accuracy\nplt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')  # Blue line for training accuracy\nplt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')  # Red line for validation accuracy\n\n# Add title and labels to the plot\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\n\n# Add a legend to differentiate between training and validation accuracy\nplt.legend()\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:59:43.821505Z","iopub.execute_input":"2023-11-09T14:59:43.821814Z","iopub.status.idle":"2023-11-09T14:59:44.144137Z","shell.execute_reply.started":"2023-11-09T14:59:43.821787Z","shell.execute_reply":"2023-11-09T14:59:44.143243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve training and validation accuracy from the training history\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# Create a list of epochs for the x-axis\nepochs = range(1, len(train_loss) + 1)\n\n# Plot the training and validation accuracy\nplt.plot(epochs, train_loss, 'b', label='Training Loss')  # Blue line for training accuracy\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')  # Red line for validation accuracy\n\n# Add title and labels to the plot\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\n# Add a legend to differentiate between training and validation accuracy\nplt.legend()\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:59:44.145658Z","iopub.execute_input":"2023-11-09T14:59:44.146331Z","iopub.status.idle":"2023-11-09T14:59:44.401230Z","shell.execute_reply.started":"2023-11-09T14:59:44.146294Z","shell.execute_reply":"2023-11-09T14:59:44.400262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# assert model.history.history.get('accuracy')[-1] > 0.80","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:59:44.402463Z","iopub.execute_input":"2023-11-09T14:59:44.402758Z","iopub.status.idle":"2023-11-09T14:59:44.406951Z","shell.execute_reply.started":"2023-11-09T14:59:44.402731Z","shell.execute_reply":"2023-11-09T14:59:44.405996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Predict using Fine-Tuned MobileNet model**","metadata":{}},{"cell_type":"markdown","source":"The following codes are inspired from \"Predict with a Fine-Tuned Neural Network with TensorFlow's Keras API\" video by deeplizard","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(x=test_batches, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:59:44.408065Z","iopub.execute_input":"2023-11-09T14:59:44.408367Z","iopub.status.idle":"2023-11-09T14:59:52.329773Z","shell.execute_reply.started":"2023-11-09T14:59:44.408343Z","shell.execute_reply":"2023-11-09T14:59:52.328885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batches.classes","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:59:52.331290Z","iopub.execute_input":"2023-11-09T14:59:52.331660Z","iopub.status.idle":"2023-11-09T14:59:52.338609Z","shell.execute_reply.started":"2023-11-09T14:59:52.331625Z","shell.execute_reply":"2023-11-09T14:59:52.337655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:59:52.339955Z","iopub.execute_input":"2023-11-09T14:59:52.340387Z","iopub.status.idle":"2023-11-09T14:59:52.352529Z","shell.execute_reply.started":"2023-11-09T14:59:52.340360Z","shell.execute_reply":"2023-11-09T14:59:52.351532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting 'normalize=True'.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n        \n    print(cm)\n    \n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape [0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                horizontalalignment=\"center\",\n                color=\"white\" if cm[i, j] > thresh else \"black\")\n        \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:59:52.353837Z","iopub.execute_input":"2023-11-09T14:59:52.354180Z","iopub.status.idle":"2023-11-09T14:59:52.365446Z","shell.execute_reply.started":"2023-11-09T14:59:52.354145Z","shell.execute_reply":"2023-11-09T14:59:52.364448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batches.class_indices","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:59:52.366797Z","iopub.execute_input":"2023-11-09T14:59:52.367626Z","iopub.status.idle":"2023-11-09T14:59:52.384127Z","shell.execute_reply.started":"2023-11-09T14:59:52.367590Z","shell.execute_reply":"2023-11-09T14:59:52.383037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define class labels for plotting the confusion matrix\ncm_plot_labels = ['Black sigatoka', 'Bunchy top', 'Healthy']\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:59:52.385626Z","iopub.execute_input":"2023-11-09T14:59:52.386048Z","iopub.status.idle":"2023-11-09T14:59:52.791704Z","shell.execute_reply.started":"2023-11-09T14:59:52.386013Z","shell.execute_reply":"2023-11-09T14:59:52.790790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\n\n# Compute the confusion matrix using ground truth classes and predicted class labels \ncm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))\n\n# Calculate the accuracy \naccuracy = accuracy_score(test_batches.classes, np.argmax(predictions, axis=1))\n\n# Convert the accuracy to a percentage \naccuracy_percentage = accuracy * 100.0\n\n# Print the test accuracy and confusion matrix \nprint(\"Test Accuracy: {:.2f}%\".format(accuracy_percentage))\nprint(\"Confusion Matrix:\")\nprint(cm)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:59:52.793085Z","iopub.execute_input":"2023-11-09T14:59:52.793501Z","iopub.status.idle":"2023-11-09T14:59:52.803915Z","shell.execute_reply.started":"2023-11-09T14:59:52.793464Z","shell.execute_reply":"2023-11-09T14:59:52.802973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the class labels for the images in the test set\ntest_classes = test_batches.classes\n\n# Make predictions on the test set\npredictions = model.predict(x=test_batches, verbose=0)\n\n# Convert the predicted probabilities to class labels\npredicted_classes = np.argmax(predictions, axis=-1)\n\n# Get the filenames of the test images\nfilenames = test_batches.filenames\n\n# Print out images along with their true and predicted labels\nfor i in range(len(filenames)):\n    print(f\"True Label: {test_classes[i]}, Predicted Label: {predicted_classes[i]}, File Name: {filenames[i]}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T14:59:52.805159Z","iopub.execute_input":"2023-11-09T14:59:52.805461Z","iopub.status.idle":"2023-11-09T15:00:00.089949Z","shell.execute_reply.started":"2023-11-09T14:59:52.805435Z","shell.execute_reply":"2023-11-09T15:00:00.088943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Saving the Model**","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:00:00.091347Z","iopub.execute_input":"2023-11-09T15:00:00.091712Z","iopub.status.idle":"2023-11-09T15:00:00.280001Z","shell.execute_reply.started":"2023-11-09T15:00:00.091676Z","shell.execute_reply":"2023-11-09T15:00:00.279113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    model.save('Laguna_Banana_Model.h5')\n    print(\"Model saved successfully.\")\nexcept Exception as e:\n    print(f\"An error occurred while saving the model: {e}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:00:00.281414Z","iopub.execute_input":"2023-11-09T15:00:00.282027Z","iopub.status.idle":"2023-11-09T15:00:00.579253Z","shell.execute_reply.started":"2023-11-09T15:00:00.281991Z","shell.execute_reply":"2023-11-09T15:00:00.578284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nnew_model = load_model('/kaggle/working/Laguna_Banana_Model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:00:00.580499Z","iopub.execute_input":"2023-11-09T15:00:00.580789Z","iopub.status.idle":"2023-11-09T15:00:01.599094Z","shell.execute_reply.started":"2023-11-09T15:00:00.580763Z","shell.execute_reply":"2023-11-09T15:00:01.598181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:00:01.606054Z","iopub.execute_input":"2023-11-09T15:00:01.606420Z","iopub.status.idle":"2023-11-09T15:00:01.845473Z","shell.execute_reply.started":"2023-11-09T15:00:01.606391Z","shell.execute_reply":"2023-11-09T15:00:01.844110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.get_weights()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:00:01.846988Z","iopub.execute_input":"2023-11-09T15:00:01.847817Z","iopub.status.idle":"2023-11-09T15:00:02.314410Z","shell.execute_reply.started":"2023-11-09T15:00:01.847781Z","shell.execute_reply":"2023-11-09T15:00:02.313414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.optimizer","metadata":{"execution":{"iopub.status.busy":"2023-11-09T15:00:02.315751Z","iopub.execute_input":"2023-11-09T15:00:02.316146Z","iopub.status.idle":"2023-11-09T15:00:02.322494Z","shell.execute_reply.started":"2023-11-09T15:00:02.316112Z","shell.execute_reply":"2023-11-09T15:00:02.321661Z"},"trusted":true},"execution_count":null,"outputs":[]}]}